{"cells":[{"cell_type":"markdown","metadata":{"cell_id":"8dd9b572c805487a9fb430fdc4ab12bb","deepnote_cell_height":156.26666259765625,"deepnote_cell_type":"markdown","id":"XUZ1dFPHzAHl"},"source":["<h1><center>Laboratorio 7: La desperaci√≥n de Mr. Lepin üêº</center></h1>\n","\n","<center><strong>MDS7202: Laboratorio de Programaci√≥n Cient√≠fica para Ciencia de Datos</strong></center>"]},{"cell_type":"markdown","metadata":{"cell_id":"d65413cd8566460dbceffcd13ca236e7","deepnote_cell_type":"markdown","id":"UD8X1uhGzAHq"},"source":["### Cuerpo Docente:\n","\n","- Profesor: Ignacio Meza, Gabriel Iturra\n","- Auxiliar: Sebasti√°n Tinoco\n","- Ayudante: Arturo Lazcano, Angel Mu√±oz"]},{"cell_type":"markdown","metadata":{"cell_id":"8e9217d02d124830a9b86046600a1605","deepnote_cell_height":172.13333129882812,"deepnote_cell_type":"markdown","id":"tXflExjqzAHr"},"source":["### Equipo: SUPER IMPORTANTE - notebooks sin nombre no ser√°n revisados\n","\n","- Nombre de alumno 1: Tom√°s Aguirre\n","- Nombre de alumno 2: Ignacio Albornoz\n"]},{"cell_type":"markdown","metadata":{"cell_id":"010402b6d5f743b885a80d2e1c6ae11a","deepnote_cell_height":62.19999694824219,"deepnote_cell_type":"markdown","id":"AD-V0bbZzAHr"},"source":["### **Link de repositorio de GitHub:** `https://github.com/tomasaguirre-ignacioalbornoz/MDS7202`"]},{"cell_type":"markdown","metadata":{"cell_id":"3abfe63b97c946e5ba1d4061b08e7913","deepnote_cell_height":165.06666564941406,"deepnote_cell_type":"markdown","id":"EcnsiQMkzAHr"},"source":["### Indice \n","\n","1. [Temas a tratar](#Temas-a-tratar:)\n","3. [Descripci√≥n del laboratorio](#Descripci√≥n-del-laboratorio.)\n","4. [Desarrollo](#Desarrollo)"]},{"cell_type":"markdown","metadata":{"cell_id":"ef0224c7a99e4b718b55493b0a1e99c4","deepnote_cell_height":724.9000244140625,"deepnote_cell_type":"markdown","id":"6uBLPj1PzAHs"},"source":["# Temas a tratar\n","\n","- Aplicar Pandas para obtener caracter√≠sticas de un DataFrame.\n","- Aplicar Pipelines.\n","- Aplicar Clusters sobre un conjunto de datos.\n","\n","## Reglas:\n","\n","- **Grupos de 2 personas**\n","- Cualquier duda fuera del horario de clases al foro. Mensajes al equipo docente ser√°n respondidos por este medio.\n","- Prohibidas las copias. \n","- Pueden usar cualquer matrial del curso que estimen conveniente.\n","- C√≥digo que no se pueda ejecutar, no ser√° revisado.\n","\n","### Objetivos principales del laboratorio\n","\n","- Comprender y aprovechar las ventajas que nos ofrece la librer√≠a `pandas` con respecto a trabajar en Python 'puro'.\n","- Crear nuevas caracter√≠sticas para entrenar un modelo de clustering.\n","- Comprender como aplicar pipelines de Scikit-Learn para generar procesos m√°s limpios.\n","\n","El laboratorio deber√° ser desarrollado sin el uso indiscriminado de iteradores nativos de python (aka \"for\", \"while\"). La idea es que aprendan a exprimir al m√°ximo las funciones optimizadas que nos entrega `numpy`, las cuales vale mencionar, son bastante m√°s eficientes que los iteradores nativos sobre arreglos (*o tensores*)."]},{"cell_type":"markdown","metadata":{"cell_id":"59664481c26f4ac4a753765269b1db6a","deepnote_cell_height":69.86666870117188,"deepnote_cell_type":"markdown","id":"wrG4gYabzAHs"},"source":["## Descripci√≥n del laboratorio."]},{"cell_type":"markdown","metadata":{"cell_id":"8c7bf8ea553d44c7a2efd61106a0bac2","deepnote_cell_height":61.866668701171875,"deepnote_cell_type":"markdown","id":"MhISwri4zAHy"},"source":["### Importamos librerias utiles üò∏"]},{"cell_type":"code","execution_count":1,"metadata":{"ExecuteTime":{"end_time":"2021-03-29T00:08:16.884674Z","start_time":"2021-03-29T00:08:16.349846Z"},"cell_id":"67b4b29f0e6b48719b58d579276f2b19","colab":{"base_uri":"https://localhost:8080/"},"deepnote_cell_height":514.13330078125,"deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"executionInfo":{"elapsed":7340,"status":"ok","timestamp":1619926444128,"user":{"displayName":"IGNACIO ALEJANDRO MEZA","photoUrl":"","userId":"17011121633069169364"},"user_tz":240},"execution_millis":8517,"execution_start":1635469788590,"id":"uyc33dKdzAHy","outputId":"275fee3c-4ef0-4bfb-acb7-e318d613bdce","source_hash":"a3741fd5"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: plotly in c:\\users\\tomas\\anaconda3\\envs\\lab_6\\lib\\site-packages (5.17.0)\n","Requirement already satisfied: tenacity>=6.2.0 in c:\\users\\tomas\\anaconda3\\envs\\lab_6\\lib\\site-packages (from plotly) (8.2.3)\n","Requirement already satisfied: packaging in c:\\users\\tomas\\anaconda3\\envs\\lab_6\\lib\\site-packages (from plotly) (23.2)\n"]}],"source":["# Libreria Core del lab.\n","import numpy as np\n","import pandas as pd\n","import datetime\n","from IPython.display import HTML\n","\n","# Libreria para plotear (En colab esta desactualizado plotly)\n","!pip install --upgrade plotly\n","import plotly.express as px\n","import plotly.graph_objects as go\n","\n","# Librerias utiles\n","from sklearn.manifold import TSNE\n","from sklearn.cluster import KMeans\n","from sklearn.base import BaseEstimator, TransformerMixin\n","from sklearn.model_selection import train_test_split \n","from sklearn.pipeline import Pipeline\n","from sklearn.compose import ColumnTransformer\n","from sklearn.preprocessing import FunctionTransformer"]},{"cell_type":"code","execution_count":2,"metadata":{"cell_id":"ce6a19ec6fc6486e832760ac3740d7ef","deepnote_cell_height":219.46665954589844,"deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":7,"execution_start":1635165625274,"id":"gQ0-zPV4NNrq","source_hash":"c60dc4a7"},"outputs":[{"name":"stdout","output_type":"stream","text":["Ignorando conexi√≥n drive-colab\n"]}],"source":["# Si usted est√° utilizando Colabolatory le puede ser √∫til este c√≥digo para cargar los archivos.\n","try:\n","    from google.colab import drive\n","    drive.mount(\"/content/drive\")\n","    path = 'Direcci√≥n donde tiene los archivos en el Drive'\n","except: \n","    print('Ignorando conexi√≥n drive-colab')"]},{"cell_type":"markdown","metadata":{"cell_id":"28c7a8b483d84878ac5a4f7ba882b711","deepnote_cell_height":133.86666870117188,"deepnote_cell_type":"markdown","id":"QDwIXTh7bK_A","owner_user_id":"badcc427-fd3d-4615-9296-faa43ec69cfb"},"source":["# Segmentaci√≥n de Clientes en Tienda de Retail üõçÔ∏è"]},{"cell_type":"markdown","metadata":{"cell_id":"6c6799ecc9e74272922d46a3b5a8b79e","deepnote_cell_height":294.683349609375,"deepnote_cell_type":"markdown","tags":[]},"source":["<p align=\"center\">\n","  <img width=300 src=\"https://s1.eestatic.com/2018/04/14/social/la_jungla_-_social_299733421_73842361_854x640.jpg\">\n","</p>"]},{"cell_type":"markdown","metadata":{"cell_id":"160bb2695f6547448bfb0f99420f952c","deepnote_cell_height":69.86666870117188,"deepnote_cell_type":"markdown","tags":[]},"source":["## 1.1 Cargar Dataset"]},{"cell_type":"markdown","metadata":{"cell_id":"48d29c89e3b6455083f8fac764f97f3b","deepnote_cell_height":475.066650390625,"deepnote_cell_type":"markdown","tags":[]},"source":["Mr. Lepin, en una nueva reuni√≥n, le cuenta a ud y su equipo que los resultados derivados del an√°lisis exploratorio de dato presentaron una gran utilidad para la empresa y que tiene un gran entusiasmo por continuar trabajando con ustedes.\n","Es por esto, que Mr. Lepin les pide que cargue y visualicen algunas de las filas que componen el Dataset.\n","A continuaci√≥n un extracto de lo parlamentado en la reuni√≥n:\n","\n","    - Usted: Es un gran logro para nuestro equipo que usted haya encontrado excelente el EDA. ¬øQu√© tiene en mente ahora?\n","    - Mr. Lepin: Resulta que hace alg√∫n tiempo, mientras tomaba un mojito en una reuni√≥n de gerentes en Panam√°, o√≠ a un *chato* acerca de **LRMFP**, que es un modelo que permite personificar a los clientes a trav√©s de la fabricaci√≥n de distintos atributos que describen a los clientes. Lo encontr√© es-tu-pendo √±atito. \n","    - Usted: Ehh bueno. Investigaremos acerca de este modelo y veremos lo que podemos hacer.\n","\n","Por ende, su siguiente tarea es calcular **LRMFP** sobre cada cliente y luego hacer un an√°lisis de las caracter√≠sticas generadas. Para esto, el √°rea de ventas les entrega un nuevo archivo llamado `online_retail_II_cleaned.pickle`, quien posee los datos del DataFrame original limpios y listos para obtener las caracter√≠sticas solicitadas por Mr. Lepin."]},{"cell_type":"code","execution_count":3,"metadata":{"cell_id":"4d7d0f0855744e6c9d5a2198e5dcd690","colab":{"base_uri":"https://localhost:8080/","height":204},"deepnote_cell_height":489.79998779296875,"deepnote_cell_type":"code","deepnote_output_heights":[177],"deepnote_to_be_reexecuted":false,"executionInfo":{"elapsed":77353,"status":"ok","timestamp":1619717831933,"user":{"displayName":"IGNACIO ALEJANDRO MEZA","photoUrl":"","userId":"17011121633069169364"},"user_tz":240},"execution_millis":466,"execution_start":1635469797118,"id":"7FNOu-CvjV5m","outputId":"90b4f92c-71df-44d4-8084-4dd06a6179e4","source_hash":"d52b246c"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Invoice</th>\n","      <th>StockCode</th>\n","      <th>Description</th>\n","      <th>Quantity</th>\n","      <th>InvoiceDate</th>\n","      <th>Price</th>\n","      <th>Customer ID</th>\n","      <th>Country</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>489434</td>\n","      <td>85048</td>\n","      <td>15CM CHRISTMAS GLASS BALL 20 LIGHTS</td>\n","      <td>12</td>\n","      <td>2009-12-01 07:45:00</td>\n","      <td>6.95</td>\n","      <td>13085.0</td>\n","      <td>United Kingdom</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>489434</td>\n","      <td>79323P</td>\n","      <td>PINK CHERRY LIGHTS</td>\n","      <td>12</td>\n","      <td>2009-12-01 07:45:00</td>\n","      <td>6.75</td>\n","      <td>13085.0</td>\n","      <td>United Kingdom</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>489434</td>\n","      <td>79323W</td>\n","      <td>WHITE CHERRY LIGHTS</td>\n","      <td>12</td>\n","      <td>2009-12-01 07:45:00</td>\n","      <td>6.75</td>\n","      <td>13085.0</td>\n","      <td>United Kingdom</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>489434</td>\n","      <td>22041</td>\n","      <td>RECORD FRAME 7\" SINGLE SIZE</td>\n","      <td>48</td>\n","      <td>2009-12-01 07:45:00</td>\n","      <td>2.10</td>\n","      <td>13085.0</td>\n","      <td>United Kingdom</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>489434</td>\n","      <td>21232</td>\n","      <td>STRAWBERRY CERAMIC TRINKET BOX</td>\n","      <td>24</td>\n","      <td>2009-12-01 07:45:00</td>\n","      <td>1.25</td>\n","      <td>13085.0</td>\n","      <td>United Kingdom</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  Invoice StockCode                          Description  Quantity  \\\n","0  489434     85048  15CM CHRISTMAS GLASS BALL 20 LIGHTS        12   \n","1  489434    79323P                   PINK CHERRY LIGHTS        12   \n","2  489434    79323W                  WHITE CHERRY LIGHTS        12   \n","3  489434     22041         RECORD FRAME 7\" SINGLE SIZE         48   \n","4  489434     21232       STRAWBERRY CERAMIC TRINKET BOX        24   \n","\n","          InvoiceDate  Price Customer ID         Country  \n","0 2009-12-01 07:45:00   6.95     13085.0  United Kingdom  \n","1 2009-12-01 07:45:00   6.75     13085.0  United Kingdom  \n","2 2009-12-01 07:45:00   6.75     13085.0  United Kingdom  \n","3 2009-12-01 07:45:00   2.10     13085.0  United Kingdom  \n","4 2009-12-01 07:45:00   1.25     13085.0  United Kingdom  "]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["df_retail = pd.read_pickle(\"online_retail_II_cleaned.pickle\")\n","df_retail = df_retail.astype(\n","    {\n","        \"Invoice\": \"category\",\n","        \"StockCode\": \"category\",\n","        \"Description\": \"category\",\n","        \"Description\": str,\n","        \"Customer ID\": \"category\",\n","        \"Country\": \"category\"\n","    }\n",")\n","df_retail.head()\n"]},{"cell_type":"markdown","metadata":{"cell_id":"060e1885d93d4325a313fded82de1921","deepnote_cell_height":109.86666870117188,"deepnote_cell_type":"markdown","tags":[]},"source":["## 1.2 Creaci√≥n de nuevas Caracteristicas [2 Puntos] "]},{"cell_type":"markdown","metadata":{"cell_id":"e650f364c9c64b079603f6d9312d2d13","deepnote_cell_height":862.933349609375,"deepnote_cell_type":"markdown","tags":[]},"source":["Como ya se les comento, Mr. Lepin esta interesado en obtener las caracter√≠sticas **LRMFP**, para esto les se√±ala que estas caracter√≠sticas se construyen en base a las siguientes definiciones:\n","\n","- **Length (L)**: Intervalo de tiempo, en d√≠as, entre la primera y la √∫ltima visita del cliente. Mientras mas grande sea el valor, mas fiel es el cliente.\n","\n","- **Recency (R)**: Indica hace cuanto tiempo el cliente realizo su ultima compra. Notar que para este caso, mientras mas grande es el valor, menos interes posee el usuario para repetir una compra en uno de los locales.\n","\n","- **Monetary (M)**: El t√©rmino \"monetario\" se refiere a la cantidad media de dinero gastada por cada visita del cliente durante el per√≠odo de observaci√≥n y refleja la contribuci√≥n del cliente a los ingresos de la empresa.\n","\n","- **Frequency (F)**: Se refiere al n√∫mero total de visitas del cliente durante el periodo de observaci√≥n. Cuanto mayor sea la frecuencia, mayor ser√° la fidelidad del cliente. \n","\n","- **Periodicity (P)**: Representa si los clientes visitan las tiendas con regularidad.\n","\n","$$Periodicity(n)=std(IVT_1, ..., IVT_n)$$\n","\n","&nbsp;&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Donde $IVT$ denota el tiempo entre visitas y n representa el n√∫mero de valores de tiempo entre visitas de un cliente.\n"," \n","\n","$$IVT_i=date\\_diff(t_{i+1},t)$$\n","\n","En base a las definiciones se√±aladas, dise√±e una funci√≥n que permita obtener las caracter√≠sticas **LRMFP** recibiendo un DataFrame como entrada. Para esto, no estar√° permitido el uso de iteradores, utilice todas las herramientas que les ofrece `pandas` para realizar esto.\n","\n","Una referencia que le puede ser √∫til es el [documento original](https://www.researchgate.net/publication/315979555_LRFMP_model_for_customer_segmentation_in_the_grocery_retail_industry_a_case_study) en donde se propone este m√©todo."]},{"cell_type":"markdown","metadata":{"cell_id":"bee8d549c7c043a5b0cafae0543afadf","deepnote_cell_height":212.6666717529297,"deepnote_cell_type":"markdown","tags":[]},"source":["**<u>Formato</u> del Resultado Esperado:**\n","\n","| Customer ID | Length | Recency | Frequency | Monetary | Periodicity |\n","|------------:|-------:|--------:|----------:|---------:|------------:|\n","|   12346.0   |    294 |      67 |        46 |   -64.68 |        37.0 |\n","|   12347.0   |     37 |       3 |        71 |  1323.32 |         0.0 |\n","|   12349.0   |    327 |      43 |       107 |  2646.99 |        78.0 |\n","|   12352.0   |     16 |      11 |        18 |   343.80 |         0.0 |\n","|   12356.0   |     44 |      16 |        84 |  3562.25 |        12.0 |"]},{"cell_type":"markdown","metadata":{"cell_id":"3c7f8a4a06a44cbd8d50e8a4decf4c71","deepnote_cell_height":52.26666259765625,"deepnote_cell_type":"markdown","tags":[]},"source":["**Respuesta:**"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"data":{"text/plain":["Index(['Invoice', 'StockCode', 'Description', 'Quantity', 'InvoiceDate',\n","       'Price', 'Customer ID', 'Country'],\n","      dtype='object')"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["df_retail.columns"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[{"data":{"text/plain":["Invoice        0\n","StockCode      0\n","Description    0\n","Quantity       0\n","InvoiceDate    0\n","Price          0\n","Customer ID    0\n","Country        0\n","dtype: int64"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["df_retail.isna().sum()"]},{"cell_type":"code","execution_count":45,"metadata":{"cell_id":"39a8b98eacdc43a4bdfeaa138b746198","deepnote_cell_height":83.86666870117188,"deepnote_cell_type":"code","owner_user_id":"8c58f50a-7a08-41a2-952e-38bdb7507048","tags":[]},"outputs":[],"source":["def custom_features(dataframe_in):\n","    resultados = []\n","    \n","    # Crear una lista de Customer IDs √∫nicos\n","    customer_ids = dataframe_in['Customer ID'].unique().astype(int)\n","    customer_ids.sort()\n","    \n","    #Calculo de length\n","    length = (dataframe_in.groupby('Customer ID')['InvoiceDate'].max() - dataframe_in.groupby('Customer ID')['InvoiceDate'].min()).dt.days\n","\n","    #Calculo de recency\n","    fecha_mas_reciente = dataframe_in['InvoiceDate'].max() + pd.DateOffset(days=1)\n","    recency = (fecha_mas_reciente - dataframe_in.groupby('Customer ID')['InvoiceDate'].max()).dt.days\n","    \n","    #Calculo de frequency\n","    frequency = dataframe_in.groupby('Customer ID')['InvoiceDate'].nunique()\n","    \n","    #Calculo de monetary\n","    monetary = dataframe_in.groupby(['Customer ID', 'InvoiceDate']).apply(lambda x: (x['Price'] * x['Quantity']).sum()).groupby('Customer ID').mean().round(2)\n","\n","    #Calculo de periodicity (ESTA NO ME ESTA DANDO, LA VOY A VER MAS ADELANTE)\n","    time_between_visits = dataframe_in.groupby('Customer ID')['InvoiceDate'].diff()\n","    periodicity = time_between_visits.dt.total_seconds().groupby(dataframe_in['Customer ID']).std()\n","\n","\n","    dataframe_out = pd.DataFrame({'Customer ID': customer_ids,\n","                                  'Length': length,\n","                                  'Recency': recency,\n","                                  'Frequency': frequency,\n","                                  'Monetary': monetary,\n","                                  'Periodicity': periodicity})\n","    return(dataframe_out)\n","    pass"]},{"cell_type":"code","execution_count":46,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Customer ID</th>\n","      <th>Length</th>\n","      <th>Recency</th>\n","      <th>Frequency</th>\n","      <th>Monetary</th>\n","      <th>Periodicity</th>\n","    </tr>\n","    <tr>\n","      <th>Customer ID</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>12346.0</th>\n","      <td>12346</td>\n","      <td>196</td>\n","      <td>165</td>\n","      <td>11</td>\n","      <td>33.90</td>\n","      <td>1.882587e+06</td>\n","    </tr>\n","    <tr>\n","      <th>12347.0</th>\n","      <td>12347</td>\n","      <td>37</td>\n","      <td>3</td>\n","      <td>2</td>\n","      <td>661.66</td>\n","      <td>3.823560e+05</td>\n","    </tr>\n","    <tr>\n","      <th>12348.0</th>\n","      <td>12348</td>\n","      <td>0</td>\n","      <td>74</td>\n","      <td>1</td>\n","      <td>222.16</td>\n","      <td>0.000000e+00</td>\n","    </tr>\n","    <tr>\n","      <th>12349.0</th>\n","      <td>12349</td>\n","      <td>181</td>\n","      <td>43</td>\n","      <td>3</td>\n","      <td>890.38</td>\n","      <td>1.408510e+06</td>\n","    </tr>\n","    <tr>\n","      <th>12351.0</th>\n","      <td>12351</td>\n","      <td>0</td>\n","      <td>11</td>\n","      <td>1</td>\n","      <td>300.93</td>\n","      <td>0.000000e+00</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>18283.0</th>\n","      <td>18283</td>\n","      <td>275</td>\n","      <td>18</td>\n","      <td>6</td>\n","      <td>103.23</td>\n","      <td>1.024230e+06</td>\n","    </tr>\n","    <tr>\n","      <th>18284.0</th>\n","      <td>18284</td>\n","      <td>0</td>\n","      <td>67</td>\n","      <td>1</td>\n","      <td>461.68</td>\n","      <td>0.000000e+00</td>\n","    </tr>\n","    <tr>\n","      <th>18285.0</th>\n","      <td>18285</td>\n","      <td>0</td>\n","      <td>296</td>\n","      <td>1</td>\n","      <td>427.00</td>\n","      <td>0.000000e+00</td>\n","    </tr>\n","    <tr>\n","      <th>18286.0</th>\n","      <td>18286</td>\n","      <td>247</td>\n","      <td>112</td>\n","      <td>2</td>\n","      <td>648.22</td>\n","      <td>2.627403e+06</td>\n","    </tr>\n","    <tr>\n","      <th>18287.0</th>\n","      <td>18287</td>\n","      <td>188</td>\n","      <td>18</td>\n","      <td>4</td>\n","      <td>586.43</td>\n","      <td>1.325988e+06</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>4314 rows √ó 6 columns</p>\n","</div>"],"text/plain":["             Customer ID  Length  Recency  Frequency  Monetary   Periodicity\n","Customer ID                                                                 \n","12346.0            12346     196      165         11     33.90  1.882587e+06\n","12347.0            12347      37        3          2    661.66  3.823560e+05\n","12348.0            12348       0       74          1    222.16  0.000000e+00\n","12349.0            12349     181       43          3    890.38  1.408510e+06\n","12351.0            12351       0       11          1    300.93  0.000000e+00\n","...                  ...     ...      ...        ...       ...           ...\n","18283.0            18283     275       18          6    103.23  1.024230e+06\n","18284.0            18284       0       67          1    461.68  0.000000e+00\n","18285.0            18285       0      296          1    427.00  0.000000e+00\n","18286.0            18286     247      112          2    648.22  2.627403e+06\n","18287.0            18287     188       18          4    586.43  1.325988e+06\n","\n","[4314 rows x 6 columns]"]},"execution_count":46,"metadata":{},"output_type":"execute_result"}],"source":["df_out = custom_features(df_retail)\n","df_out"]},{"cell_type":"code","execution_count":47,"metadata":{},"outputs":[{"data":{"text/plain":["Customer ID      0\n","Length           0\n","Recency          0\n","Frequency        0\n","Monetary         0\n","Periodicity    148\n","dtype: int64"]},"execution_count":47,"metadata":{},"output_type":"execute_result"}],"source":["df_out.isna().sum()"]},{"cell_type":"markdown","metadata":{"cell_id":"e227578abc624b36bedcf300ab03dec3","deepnote_cell_height":52.26666259765625,"deepnote_cell_type":"markdown","tags":[]},"source":["**Res√∫esta de Pauta:**"]},{"cell_type":"markdown","metadata":{"cell_id":"e4adca3e05c741df93087e2a0638ef7d","deepnote_cell_height":69.86666870117188,"deepnote_cell_type":"markdown","tags":[]},"source":["## 1.3 Pipelines üë∑"]},{"cell_type":"markdown","metadata":{"cell_id":"20e2c59abf64489d8cabc5c230e86fd2","deepnote_cell_height":133.46665954589844,"deepnote_cell_type":"markdown","tags":[]},"source":["Finalmente *Don Mora* le pregunta si seria posible realizar un pipeline para realizar una segmentaci√≥n de los clientes con los nuevos datos generados, a lo que usted responde que **s√≠** y propone la utilizaci√≥n de k-means para la segmentaci√≥n.\n","\n","A continuaci√≥n siga los pasos requeridos para obtener la segmentaci√≥n de clientes."]},{"cell_type":"markdown","metadata":{"cell_id":"c6162b8b49a045bba12f9b17b51f21bf","deepnote_cell_height":61.866668701171875,"deepnote_cell_type":"markdown","tags":[]},"source":["### 1.3.1 Estandarizar Caracteristicas [0.5 puntos]"]},{"cell_type":"markdown","metadata":{"cell_id":"94c48775ecb4496d970fbd920f65c126","deepnote_cell_height":268.70001220703125,"deepnote_cell_type":"markdown","tags":[]},"source":["Construya una clase llamada ``MinMax()`` utilizando ``BaseEstimator`` y ``TransformerMixin`` para realizar una transformaci√≥n de cada una de las columnas de un DataFrame utilizando ``ColumnTransformer()`` m√°s tarde (tome como referencia el siguiente [enlace](https://sklearn-template.readthedocs.io/en/latest/user_guide.html#transformer)).\n","\n","\n"," Para esto considere que Min-Max escaler queda dada por la ecuaci√≥n:\n","\n","$$MinMax = \\dfrac{x-min(x)}{max(x) - min(x)}$$\n","\n","Con esto buscamos que los valores que componen a las columnas se muevan en el rango de valores $[0, 1]$."]},{"cell_type":"markdown","metadata":{"cell_id":"c087d1fa8aa94d7485fe1292bf628660","deepnote_cell_height":52.26666259765625,"deepnote_cell_type":"markdown","tags":[]},"source":["**Respuesta:**"]},{"cell_type":"code","execution_count":14,"metadata":{"cell_id":"07cb4dcf097c4c6baabb9ae2bda25caf","deepnote_cell_height":83.86666870117188,"deepnote_cell_type":"code","tags":[]},"outputs":[],"source":["class MinMax(BaseEstimator, TransformerMixin):\n","    def __init__(self):\n","        pass\n","\n","    def fit(self, X, y=None):\n","        return self\n","\n","    def transform(self, X):\n","        min_val = X.min()\n","        max_val = X.max()\n","        scaled_data = (X - min_val) / (max_val - min_val)\n","        return scaled_data"]},{"cell_type":"markdown","metadata":{"cell_id":"b280dbe181ce4d80a6a5b5f563c842e7","deepnote_cell_height":62.19999694824219,"deepnote_cell_type":"markdown","tags":[]},"source":["### 1.3.2 `T-SNE` Pipeline [1.0 puntos]"]},{"cell_type":"markdown","metadata":{"cell_id":"c532e63f2fd541cda5b741d2f24c1ea8","deepnote_cell_height":413.8666687011719,"deepnote_cell_type":"markdown","tags":[]},"source":["Para comenzar introduci√©ndose en el uso de pipeline, decide probar realizando un pipeline enfocado en la reducci√≥n de dimensionalidad y as√≠ hacer no decepcionar a Mr. Lepin con la clusterizaci√≥n del modelo. \n","\n","Configure un pipeline utilizando el algoritmo `T-SNE` sobre los datos **LRMFP**, donde, para la realizaci√≥n del pipeline considera los siguientes pasos:\n","\n","1. Como primer paso obtenga las caracter√≠sticas **LRMFP** desde el DataFrame ``df_retail_II_cleaned.pickle`` utilizando la funci√≥n ``custom_features`` creada anteriormente, junto a ``FunctionTransformer()``. Considere esto como el primer paso de su pipeline.\n","2. En segundo lugar usando ``ColumnTransformer()`` aplique el MinxMax scaler creado por usted sobre todas las columnas generadas en el paso anterior. \n","3. Finalmente, aplique un √∫ltimo paso donde obtiene las 2 componentes m√°s relevantes utilizando el algoritmo `T-SNE` de sckit-learn.\n","\n","Tras aplicar las transformaciones sobre el dataset **LRMFP**, gr√°fique las componentes obtenidas en la reducci√≥n de dimensionalidad."]},{"cell_type":"markdown","metadata":{"cell_id":"a480355952a34b6cb7e72afa764091d6","deepnote_cell_height":52.26666259765625,"deepnote_cell_type":"markdown","tags":[]},"source":["**Respuesta:**"]},{"cell_type":"code","execution_count":16,"metadata":{"cell_id":"1889976b7a4c40c7825752979b577567","deepnote_cell_height":65.86666870117188,"deepnote_cell_type":"code","tags":[]},"outputs":[{"ename":"ValueError","evalue":"Input X contains NaN.\nTSNE does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[1;32mc:\\Users\\tomas\\OneDrive - Universidad de Chile\\Semestre 2023-2 Archivos\\Laboratorio de Programaci√≥n Cient√≠fica\\Laboratorios\\Github\\MDS7202\\lab7\\Laboratorio7_Enunciado.ipynb Cell 34\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/tomas/OneDrive%20-%20Universidad%20de%20Chile/Semestre%202023-2%20Archivos/Laboratorio%20de%20Programaci%C3%B3n%20Cient%C3%ADfica/Laboratorios/Github/MDS7202/lab7/Laboratorio7_Enunciado.ipynb#X44sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m tsne \u001b[39m=\u001b[39m TSNE(n_components\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m, random_state\u001b[39m=\u001b[39m\u001b[39m314159\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/tomas/OneDrive%20-%20Universidad%20de%20Chile/Semestre%202023-2%20Archivos/Laboratorio%20de%20Programaci%C3%B3n%20Cient%C3%ADfica/Laboratorios/Github/MDS7202/lab7/Laboratorio7_Enunciado.ipynb#X44sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m pipeline \u001b[39m=\u001b[39m Pipeline([(\u001b[39m'\u001b[39m\u001b[39mdf_out\u001b[39m\u001b[39m'\u001b[39m, fn_custom_features),\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/tomas/OneDrive%20-%20Universidad%20de%20Chile/Semestre%202023-2%20Archivos/Laboratorio%20de%20Programaci%C3%B3n%20Cient%C3%ADfica/Laboratorios/Github/MDS7202/lab7/Laboratorio7_Enunciado.ipynb#X44sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m                      (\u001b[39m'\u001b[39m\u001b[39mMinMax\u001b[39m\u001b[39m'\u001b[39m, column_transformer),\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/tomas/OneDrive%20-%20Universidad%20de%20Chile/Semestre%202023-2%20Archivos/Laboratorio%20de%20Programaci%C3%B3n%20Cient%C3%ADfica/Laboratorios/Github/MDS7202/lab7/Laboratorio7_Enunciado.ipynb#X44sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m                      (\u001b[39m'\u001b[39m\u001b[39mTSNE\u001b[39m\u001b[39m'\u001b[39m, tsne)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/tomas/OneDrive%20-%20Universidad%20de%20Chile/Semestre%202023-2%20Archivos/Laboratorio%20de%20Programaci%C3%B3n%20Cient%C3%ADfica/Laboratorios/Github/MDS7202/lab7/Laboratorio7_Enunciado.ipynb#X44sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m                      ])\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/tomas/OneDrive%20-%20Universidad%20de%20Chile/Semestre%202023-2%20Archivos/Laboratorio%20de%20Programaci%C3%B3n%20Cient%C3%ADfica/Laboratorios/Github/MDS7202/lab7/Laboratorio7_Enunciado.ipynb#X44sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m lrmfp \u001b[39m=\u001b[39m pipeline\u001b[39m.\u001b[39;49mfit_transform(df_retail)\n","File \u001b[1;32mc:\\Users\\tomas\\anaconda3\\envs\\Lab_6\\Lib\\site-packages\\sklearn\\base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[0;32m   1147\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[0;32m   1148\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[0;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1150\u001b[0m     )\n\u001b[0;32m   1151\u001b[0m ):\n\u001b[1;32m-> 1152\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n","File \u001b[1;32mc:\\Users\\tomas\\anaconda3\\envs\\Lab_6\\Lib\\site-packages\\sklearn\\pipeline.py:479\u001b[0m, in \u001b[0;36mPipeline.fit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    477\u001b[0m fit_params_last_step \u001b[39m=\u001b[39m fit_params_steps[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m][\u001b[39m0\u001b[39m]]\n\u001b[0;32m    478\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(last_step, \u001b[39m\"\u001b[39m\u001b[39mfit_transform\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m--> 479\u001b[0m     \u001b[39mreturn\u001b[39;00m last_step\u001b[39m.\u001b[39;49mfit_transform(Xt, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params_last_step)\n\u001b[0;32m    480\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    481\u001b[0m     \u001b[39mreturn\u001b[39;00m last_step\u001b[39m.\u001b[39mfit(Xt, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params_last_step)\u001b[39m.\u001b[39mtransform(Xt)\n","File \u001b[1;32mc:\\Users\\tomas\\anaconda3\\envs\\Lab_6\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:157\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    155\u001b[0m \u001b[39m@wraps\u001b[39m(f)\n\u001b[0;32m    156\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m--> 157\u001b[0m     data_to_wrap \u001b[39m=\u001b[39m f(\u001b[39mself\u001b[39;49m, X, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    158\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_to_wrap, \u001b[39mtuple\u001b[39m):\n\u001b[0;32m    159\u001b[0m         \u001b[39m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    160\u001b[0m         return_tuple \u001b[39m=\u001b[39m (\n\u001b[0;32m    161\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[39m0\u001b[39m], X, \u001b[39mself\u001b[39m),\n\u001b[0;32m    162\u001b[0m             \u001b[39m*\u001b[39mdata_to_wrap[\u001b[39m1\u001b[39m:],\n\u001b[0;32m    163\u001b[0m         )\n","File \u001b[1;32mc:\\Users\\tomas\\anaconda3\\envs\\Lab_6\\Lib\\site-packages\\sklearn\\base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[0;32m   1147\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[0;32m   1148\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[0;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1150\u001b[0m     )\n\u001b[0;32m   1151\u001b[0m ):\n\u001b[1;32m-> 1152\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n","File \u001b[1;32mc:\\Users\\tomas\\anaconda3\\envs\\Lab_6\\Lib\\site-packages\\sklearn\\manifold\\_t_sne.py:1111\u001b[0m, in \u001b[0;36mTSNE.fit_transform\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m   1090\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Fit X into an embedded space and return that transformed output.\u001b[39;00m\n\u001b[0;32m   1091\u001b[0m \n\u001b[0;32m   1092\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1108\u001b[0m \u001b[39m    Embedding of the training data in low-dimensional space.\u001b[39;00m\n\u001b[0;32m   1109\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1110\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_params_vs_input(X)\n\u001b[1;32m-> 1111\u001b[0m embedding \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit(X)\n\u001b[0;32m   1112\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membedding_ \u001b[39m=\u001b[39m embedding\n\u001b[0;32m   1113\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membedding_\n","File \u001b[1;32mc:\\Users\\tomas\\anaconda3\\envs\\Lab_6\\Lib\\site-packages\\sklearn\\manifold\\_t_sne.py:841\u001b[0m, in \u001b[0;36mTSNE._fit\u001b[1;34m(self, X, skip_num_points)\u001b[0m\n\u001b[0;32m    838\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlearning_rate_ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlearning_rate\n\u001b[0;32m    840\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmethod \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbarnes_hut\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m--> 841\u001b[0m     X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(\n\u001b[0;32m    842\u001b[0m         X,\n\u001b[0;32m    843\u001b[0m         accept_sparse\u001b[39m=\u001b[39;49m[\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[0;32m    844\u001b[0m         ensure_min_samples\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m,\n\u001b[0;32m    845\u001b[0m         dtype\u001b[39m=\u001b[39;49m[np\u001b[39m.\u001b[39;49mfloat32, np\u001b[39m.\u001b[39;49mfloat64],\n\u001b[0;32m    846\u001b[0m     )\n\u001b[0;32m    847\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    848\u001b[0m     X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_data(\n\u001b[0;32m    849\u001b[0m         X, accept_sparse\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mcsr\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mcsc\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mcoo\u001b[39m\u001b[39m\"\u001b[39m], dtype\u001b[39m=\u001b[39m[np\u001b[39m.\u001b[39mfloat32, np\u001b[39m.\u001b[39mfloat64]\n\u001b[0;32m    850\u001b[0m     )\n","File \u001b[1;32mc:\\Users\\tomas\\anaconda3\\envs\\Lab_6\\Lib\\site-packages\\sklearn\\base.py:605\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    603\u001b[0m         out \u001b[39m=\u001b[39m X, y\n\u001b[0;32m    604\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m no_val_y:\n\u001b[1;32m--> 605\u001b[0m     out \u001b[39m=\u001b[39m check_array(X, input_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mX\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcheck_params)\n\u001b[0;32m    606\u001b[0m \u001b[39melif\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_y:\n\u001b[0;32m    607\u001b[0m     out \u001b[39m=\u001b[39m _check_y(y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_params)\n","File \u001b[1;32mc:\\Users\\tomas\\anaconda3\\envs\\Lab_6\\Lib\\site-packages\\sklearn\\utils\\validation.py:957\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    951\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    952\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mFound array with dim \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m expected <= 2.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    953\u001b[0m             \u001b[39m%\u001b[39m (array\u001b[39m.\u001b[39mndim, estimator_name)\n\u001b[0;32m    954\u001b[0m         )\n\u001b[0;32m    956\u001b[0m     \u001b[39mif\u001b[39;00m force_all_finite:\n\u001b[1;32m--> 957\u001b[0m         _assert_all_finite(\n\u001b[0;32m    958\u001b[0m             array,\n\u001b[0;32m    959\u001b[0m             input_name\u001b[39m=\u001b[39;49minput_name,\n\u001b[0;32m    960\u001b[0m             estimator_name\u001b[39m=\u001b[39;49mestimator_name,\n\u001b[0;32m    961\u001b[0m             allow_nan\u001b[39m=\u001b[39;49mforce_all_finite \u001b[39m==\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mallow-nan\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    962\u001b[0m         )\n\u001b[0;32m    964\u001b[0m \u001b[39mif\u001b[39;00m ensure_min_samples \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    965\u001b[0m     n_samples \u001b[39m=\u001b[39m _num_samples(array)\n","File \u001b[1;32mc:\\Users\\tomas\\anaconda3\\envs\\Lab_6\\Lib\\site-packages\\sklearn\\utils\\validation.py:122\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[39mif\u001b[39;00m first_pass_isfinite:\n\u001b[0;32m    120\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m _assert_all_finite_element_wise(\n\u001b[0;32m    123\u001b[0m     X,\n\u001b[0;32m    124\u001b[0m     xp\u001b[39m=\u001b[39;49mxp,\n\u001b[0;32m    125\u001b[0m     allow_nan\u001b[39m=\u001b[39;49mallow_nan,\n\u001b[0;32m    126\u001b[0m     msg_dtype\u001b[39m=\u001b[39;49mmsg_dtype,\n\u001b[0;32m    127\u001b[0m     estimator_name\u001b[39m=\u001b[39;49mestimator_name,\n\u001b[0;32m    128\u001b[0m     input_name\u001b[39m=\u001b[39;49minput_name,\n\u001b[0;32m    129\u001b[0m )\n","File \u001b[1;32mc:\\Users\\tomas\\anaconda3\\envs\\Lab_6\\Lib\\site-packages\\sklearn\\utils\\validation.py:171\u001b[0m, in \u001b[0;36m_assert_all_finite_element_wise\u001b[1;34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    154\u001b[0m \u001b[39mif\u001b[39;00m estimator_name \u001b[39mand\u001b[39;00m input_name \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mX\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mand\u001b[39;00m has_nan_error:\n\u001b[0;32m    155\u001b[0m     \u001b[39m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[0;32m    156\u001b[0m     \u001b[39m# scikit-learn.\u001b[39;00m\n\u001b[0;32m    157\u001b[0m     msg_err \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (\n\u001b[0;32m    158\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mestimator_name\u001b[39m}\u001b[39;00m\u001b[39m does not accept missing values\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    159\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    169\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m#estimators-that-handle-nan-values\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    170\u001b[0m     )\n\u001b[1;32m--> 171\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(msg_err)\n","\u001b[1;31mValueError\u001b[0m: Input X contains NaN.\nTSNE does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"]}],"source":["# 1.\n","fn_custom_features = FunctionTransformer(func=custom_features)\n","\n","# 2. \n","column_transformer = ColumnTransformer(\n","    transformers=[\n","        ('minmax', MinMax(), ['Length', 'Recency', 'Frequency', 'Monetary', 'Periodicity']),  \n","    ],\n","    remainder='passthrough' \n",")\n","\n","# 3.\n","tsne = TSNE(n_components=2, random_state=314159)\n","\n","\n","pipeline = Pipeline([('df_out', fn_custom_features),\n","                     ('MinMax', column_transformer),\n","                     ('TSNE', tsne)\n","                     ])\n","\n","lrmfp = pipeline.fit_transform(df_retail)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["fig = px.scatter(lrmfp, x='Componente 1', y='Componente 2', title='Gr√°fico de Componentes Principales')\n","fig.show()"]},{"cell_type":"markdown","metadata":{"cell_id":"75015b8bec9f4985ae3535276edb9cf6","deepnote_cell_height":61.866668701171875,"deepnote_cell_type":"markdown","tags":[]},"source":["### 1.3.3 Clustering"]},{"cell_type":"markdown","metadata":{"cell_id":"01eb144ba7b844c98b0f68dc07f1ba38","deepnote_cell_height":53.866668701171875,"deepnote_cell_type":"markdown","tags":[]},"source":["#### 1.3.3.1 M√©todo del Codo [1 puntos]"]},{"cell_type":"markdown","metadata":{"cell_id":"de1f59f512af42618d3a5b084f84b460","deepnote_cell_height":223.06666564941406,"deepnote_cell_type":"markdown","tags":[]},"source":["Utilizando la clase creada para escalamiento, aplique el m√©todo del codo para visualizar cual es el n√∫mero de clusters que mejor se ajustan a los datos. Realice esto utilizando el algoritmo K-means dentro de un pipeline para un $k \\in [1,20]$, donde k representa el n√∫mero de clusters del k-means. Para la realizaci√≥n de esta secci√≥n y la pr√≥xima (1.3.3.2), considere los mismos pasos utilizados para el t-sne, pero **permutando el algoritmo de reducci√≥n de dimensionalidad por k-means.**\n","\n","A trav√©s del grafico obtenido, comente y justifique que valor de k escoger√≠a para realizar el k-means."]},{"cell_type":"markdown","metadata":{"cell_id":"a268dbe1c26b4dccbaa8c976005c9141","deepnote_cell_height":52.26666259765625,"deepnote_cell_type":"markdown","tags":[]},"source":["**Respuesta:**"]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"36239002cba54f98a3778e66878b1041","deepnote_cell_height":65.86666870117188,"deepnote_cell_type":"code","tags":[]},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"cell_id":"3bb5d86bc1e54cf18a851e71c2c3a3c1","deepnote_cell_height":53.866668701171875,"deepnote_cell_type":"markdown","tags":[]},"source":["#### 1.3.3.2 Segmentaci√≥n de Clientes con K-Means üéÅ [1 punto]"]},{"cell_type":"markdown","metadata":{"cell_id":"f8c3b4d105754ccb8a1ce6dfd606a40e","deepnote_cell_height":200.6666717529297,"deepnote_cell_type":"markdown","tags":[]},"source":["En base a la elecci√≥n de k realizada en la secci√≥n anterior, utilice este valor escogido y entrene un modelo de K-means utilizando el mismo pipeline de scikit-learn utilizado anteriormente.\n","\n","Una vez ajustado los datos, genere una tabla con los promedios (o medianas) para cada uno de los atributos, agrupando estos por el cl√∫ster que pertenecen. ¬øEs posible observar agrupaciones coherentes?, ¬øQu√© tipo de clientes posee el retail?, Justifique su respuesta y no decepcione a Mr. Lepin.\n"]},{"cell_type":"markdown","metadata":{"cell_id":"dbce893901024a828d2b875798e27674","deepnote_cell_height":52.26666259765625,"deepnote_cell_type":"markdown","tags":[]},"source":["**Respuesta:**"]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"375d5f6e310c442d82a9c940805fc6d2","deepnote_cell_height":65.86666870117188,"deepnote_cell_type":"code","tags":[]},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"cell_id":"18e50ee0240543d692bcde6d9c29fe73","deepnote_cell_height":261.4666748046875,"deepnote_cell_type":"markdown","tags":[]},"source":["**Respuesta Esperada:**\n","\n","|         | Length  | Recency   | Frequency | Monetary | Periodicity |       |\n","|---------|---------|-----------|----------|-------------|-------|-------|\n","| Cluster |         |           |          |             |       |       |\n","|    0    |   258.8 |      45.2 |     76.1 |      1107.7 | 107.6 |   449 |\n","|    1    |    76.1 |     217.6 |     45.5 |       791.7 |  14.1 |   466 |\n","|    2    |   368.5 |       4.8 |   2715.0 |    226621.6 |   4.2 |     4 |\n","|    3    |    85.3 |      45.7 |     65.8 |      1047.0 |  10.5 |   987 |\n","|    4    |   347.2 |      15.9 |   1658.0 |     35829.3 |   8.0 |    25 |\n","|    5    |   298.0 |      29.8 |    183.8 |      3639.9 |  32.0 |  1188 |"]},{"cell_type":"markdown","metadata":{"cell_id":"f79d1fa6b1a64b6f97bffc62b037a663","deepnote_cell_height":53.866668701171875,"deepnote_cell_type":"markdown","tags":[]},"source":["#### 1.3.3.3 Plot de K-Means üìà [0.5 puntos]\n","\n"]},{"cell_type":"markdown","metadata":{"cell_id":"2d0348435e814f16b8957dfbc6384a88","deepnote_cell_height":192.26666259765625,"deepnote_cell_type":"markdown","owner_user_id":"d50c3174-babb-4861-9c71-7e3af66458b8","tags":[]},"source":["Por √∫ltimo, Mr. Lepin, impaciente de no entender lo que usted intenta explicarle, le solicita que por favor muestre alg√∫n resultado \"visual\" de los grupos encontrados.\n","\n","Para esto, grafique nuevamente las caracter√≠sticas encontradas usando `T-SNE` (no calcule de nuevo, simplemente utilice las proyecciones encontradas) y agregue las labels calculadas con kmeans como el argumento `color`.   \n","\n","Comente: ¬øSe separan bien los distintos clusters en la visualizaci√≥n?\n"]},{"cell_type":"markdown","metadata":{"cell_id":"e805388b96c04ea8a06a262229c2f799","deepnote_cell_height":52.26666259765625,"deepnote_cell_type":"markdown","tags":[]},"source":["**Respuesta:**"]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"9e2d26de81ed4a729e25c6c5361310e1","deepnote_cell_height":65.86666870117188,"deepnote_cell_type":"code","tags":[]},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"cell_id":"94721075d5ff44bd83601c871797ae2a","deepnote_cell_height":514.4666748046875,"deepnote_cell_type":"markdown","id":"Rg4ZMq8ezAH6"},"source":["# Conclusi√≥n\n","Eso ha sido todo para el lab de hoy, recuerden que el laboratorio tiene un plazo de entrega de una semana. Cualquier duda del laboratorio, no duden en contactarnos por correo, Discord o U-cursos.\n","\n","![Gracias Totales!](https://i.pinimg.com/originals/65/ae/27/65ae270df87c3c4adcea997e48f60852.gif \"bruno\")\n"]},{"cell_type":"markdown","metadata":{"cell_id":"7e31a91f8cb744cabd0ed0287ac5257e","deepnote_cell_height":171.28334045410156,"deepnote_cell_type":"markdown","id":"wCL1lACBzAH7"},"source":["<br>\n","<center>\n","<img src=\"https://i.kym-cdn.com/photos/images/original/001/194/195/b18.png\" width=100 height=50 />\n","</center>\n","<br>"]},{"cell_type":"markdown","metadata":{"created_in_deepnote_cell":true,"deepnote_cell_type":"markdown"},"source":["<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=87110296-876e-426f-b91d-aaf681223468' target=\"_blank\">\n","<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\n","Created in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>"]}],"metadata":{"colab":{"collapsed_sections":["Rcjs-dd1V-1u","dkyp81nkBghF","THmFfYs1AhAW"],"name":"Copia de Tarea1.ipynb","provenance":[],"toc_visible":true},"deepnote":{},"deepnote_execution_queue":[],"deepnote_notebook_id":"33c253a4f84d40a091bd5023e95abb64","kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":true,"title_cell":"Tabla de Contenidos","title_sidebar":"Contenidos","toc_cell":false,"toc_position":{"height":"calc(100% - 180px)","left":"10px","top":"150px","width":"241.867px"},"toc_section_display":true,"toc_window_display":true},"varInspector":{"cols":{"lenName":16,"lenType":16,"lenVar":40},"kernels_config":{"python":{"delete_cmd_postfix":"","delete_cmd_prefix":"del ","library":"var_list.py","varRefreshCmd":"print(var_dic_list())"},"r":{"delete_cmd_postfix":") ","delete_cmd_prefix":"rm(","library":"var_list.r","varRefreshCmd":"cat(var_dic_list()) "}},"types_to_exclude":["module","function","builtin_function_or_method","instance","_Feature"],"window_display":false}},"nbformat":4,"nbformat_minor":0}
